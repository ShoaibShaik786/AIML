{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE-221710302060-Shaik Shoaib Aslam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
       "      <td>dharma pal</td>\n",
       "      <td>2015-05-29T02:30:18.971000</td>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
       "      <td>Tiza Arellano</td>\n",
       "      <td>2015-05-29T00:14:48.748000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
       "      <td>Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿</td>\n",
       "      <td>2015-05-28T21:00:08.607000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12icv3ysqvlwth2c23eddlykyqut5z1h</td>\n",
       "      <td>Eric Gonzalez</td>\n",
       "      <td>2015-05-28T20:47:12.193000</td>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133stly3kete3tly22petvwdpmghrlli</td>\n",
       "      <td>Analena López</td>\n",
       "      <td>2015-05-28T17:08:29.827000</td>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID                              AUTHOR  \\\n",
       "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
       "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
       "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
       "3      z12icv3ysqvlwth2c23eddlykyqut5z1h                       Eric Gonzalez   \n",
       "4      z133stly3kete3tly22petvwdpmghrlli                       Analena López   \n",
       "\n",
       "                         DATE  \\\n",
       "0  2015-05-29T02:30:18.971000   \n",
       "1  2015-05-29T00:14:48.748000   \n",
       "2  2015-05-28T21:00:08.607000   \n",
       "3  2015-05-28T20:47:12.193000   \n",
       "4  2015-05-28T17:08:29.827000   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0                                         Nice song﻿      0  \n",
       "1                                      I love song ﻿      0  \n",
       "2                                      I love song ﻿      0  \n",
       "3  860,000,000 lets make it first female to reach...      0  \n",
       "4                      shakira is best for worldcup﻿      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/sumathi16/Datasets/master/Youtube05-Shakira.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new data frame with required columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.drop(['COMMENT_ID','AUTHOR','DATE'],axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  CLASS\n",
       "0                                         Nice song﻿      0\n",
       "1                                      I love song ﻿      0\n",
       "2                                      I love song ﻿      0\n",
       "3  860,000,000 lets make it first female to reach...      0\n",
       "4                      shakira is best for worldcup﻿      0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values if there are any remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONTENT    0\n",
       "CLASS      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # No Missing Values found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a count plot using seaborn for the column Class. Check how many records are there for spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x264d62f9648>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    196\n",
       "1    174\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations :\n",
    "    0 represents spam ans 1 represents ham\n",
    "    There are more spam records than ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words and ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply CountVectorizer on the column Content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.CONTENT,df.CLASS,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count1 = count_vect.fit(X_train)\n",
    "word_count2 = count_vect.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0687119038',\n",
       " '10',\n",
       " '100',\n",
       " '15',\n",
       " '19',\n",
       " '1billiom',\n",
       " '25',\n",
       " '35',\n",
       " '39',\n",
       " '4000',\n",
       " '4netjobs',\n",
       " '500',\n",
       " '5000',\n",
       " '50k',\n",
       " '9nl',\n",
       " 'account',\n",
       " 'acidic',\n",
       " 'adam',\n",
       " 'adele',\n",
       " 'adf',\n",
       " 'advertise',\n",
       " 'advertisements',\n",
       " 'afflicted',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'album',\n",
       " 'all',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alvar',\n",
       " 'am',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angels',\n",
       " 'animation',\n",
       " 'animator',\n",
       " 'another',\n",
       " 'any',\n",
       " 'apostles',\n",
       " 'app',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'apprecitate',\n",
       " 'apps',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'aunt',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'band',\n",
       " 'bass',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'been',\n",
       " 'begin',\n",
       " 'behavior',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'br',\n",
       " 'brazil',\n",
       " 'but',\n",
       " 'button',\n",
       " 'by',\n",
       " 'called',\n",
       " 'can',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'cents',\n",
       " 'chance',\n",
       " 'channel',\n",
       " 'check',\n",
       " 'choice',\n",
       " 'christians',\n",
       " 'click',\n",
       " 'close',\n",
       " 'code',\n",
       " 'columbus',\n",
       " 'com',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comforter',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'compared',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'conceived',\n",
       " 'conciliate',\n",
       " 'confessors',\n",
       " 'continue',\n",
       " 'cool',\n",
       " 'could',\n",
       " 'countless',\n",
       " 'country',\n",
       " 'cover',\n",
       " 'covers',\n",
       " 'cup',\n",
       " 'currently',\n",
       " 'cutie',\n",
       " 'cyrus',\n",
       " 'daily',\n",
       " 'dance',\n",
       " 'day',\n",
       " 'decided',\n",
       " 'del',\n",
       " 'demonstrating',\n",
       " 'did',\n",
       " 'different',\n",
       " 'disliked',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'download',\n",
       " 'dragons',\n",
       " 'drake',\n",
       " 'dreaming',\n",
       " 'dribbleproshot',\n",
       " 'drums',\n",
       " 'dubstep',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'edge',\n",
       " 'em',\n",
       " 'enjoy',\n",
       " 'enormously',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'experience',\n",
       " 'extraordinary',\n",
       " 'facebook',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fans',\n",
       " 'fast',\n",
       " 'fausto',\n",
       " 'faves',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'few',\n",
       " 'find',\n",
       " 'first',\n",
       " 'football',\n",
       " 'for',\n",
       " 'forget',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'foward',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'friends',\n",
       " 'from',\n",
       " 'fuck',\n",
       " 'fyi',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'good',\n",
       " 'google',\n",
       " 'grass',\n",
       " 'great',\n",
       " 'gt',\n",
       " 'guitar',\n",
       " 'guys',\n",
       " 'hahahahah',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'her',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'highly',\n",
       " 'hips',\n",
       " 'hiring',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'if',\n",
       " 'im2458444',\n",
       " 'imagine',\n",
       " 'immediately',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'income',\n",
       " 'independent',\n",
       " 'industry',\n",
       " 'inspire',\n",
       " 'instrumental',\n",
       " 'into',\n",
       " 'investment',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jobs',\n",
       " 'johnny',\n",
       " 'join',\n",
       " 'juno',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'keyboards',\n",
       " 'kind',\n",
       " 'kld3y',\n",
       " 'kluivert',\n",
       " 'know',\n",
       " 'kodaline',\n",
       " 'lake',\n",
       " 'lana',\n",
       " 'languages',\n",
       " 'least',\n",
       " 'lets',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'liking',\n",
       " 'listen',\n",
       " 'listener',\n",
       " 'live',\n",
       " 'lol',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'love',\n",
       " 'lt',\n",
       " 'ly',\n",
       " 'lyrics',\n",
       " 'macklemore',\n",
       " 'made',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'many',\n",
       " 'martyrs',\n",
       " 'master',\n",
       " 'mate',\n",
       " 'mates',\n",
       " 'me',\n",
       " 'means',\n",
       " 'media',\n",
       " 'meet',\n",
       " 'mess',\n",
       " 'miley',\n",
       " 'million',\n",
       " 'mind',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'mississippi',\n",
       " 'mixtape',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'movement',\n",
       " 'much',\n",
       " 'music',\n",
       " 'musician',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'number',\n",
       " 'numberless',\n",
       " 'nummber',\n",
       " 'of',\n",
       " 'off',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'on',\n",
       " 'one',\n",
       " 'online',\n",
       " 'only',\n",
       " 'opportunity',\n",
       " 'or',\n",
       " 'original',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'page',\n",
       " 'paid',\n",
       " 'part',\n",
       " 'pass',\n",
       " 'passionate',\n",
       " 'patriarchs',\n",
       " 'patrik',\n",
       " 'peace',\n",
       " 'peaceful',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perfect',\n",
       " 'person',\n",
       " 'piano',\n",
       " 'picture',\n",
       " 'pink',\n",
       " 'plausible',\n",
       " 'play',\n",
       " 'player',\n",
       " 'please',\n",
       " 'pray',\n",
       " 'prior',\n",
       " 'probably',\n",
       " 'promotes',\n",
       " 'prophets',\n",
       " 'prove',\n",
       " 'psn',\n",
       " 'queen',\n",
       " 'quot',\n",
       " 'range',\n",
       " 're',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'realized',\n",
       " 'really',\n",
       " 'recognizes',\n",
       " 'record',\n",
       " 'regret',\n",
       " 'remember',\n",
       " 'replay',\n",
       " 'requite',\n",
       " 'rey',\n",
       " 'right',\n",
       " 'rosary',\n",
       " 'saints',\n",
       " 'search',\n",
       " 'seat',\n",
       " 'seconds',\n",
       " 'see',\n",
       " 'shakifans',\n",
       " 'shakira',\n",
       " 'share',\n",
       " 'she',\n",
       " 'should',\n",
       " 'sign',\n",
       " 'simple',\n",
       " 'simply',\n",
       " 'sin',\n",
       " 'sing',\n",
       " 'singer',\n",
       " 'sites',\n",
       " 'skills',\n",
       " 'small',\n",
       " 'so',\n",
       " 'soccer',\n",
       " 'social',\n",
       " 'some',\n",
       " 'son',\n",
       " 'song',\n",
       " 'songs',\n",
       " 'songwriter',\n",
       " 'soo',\n",
       " 'sorry',\n",
       " 'spam',\n",
       " 'spamming',\n",
       " 'spare',\n",
       " 'speaks',\n",
       " 'special',\n",
       " 'speech',\n",
       " 'spending',\n",
       " 'spirits',\n",
       " 'start',\n",
       " 'statement',\n",
       " 'step',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'store',\n",
       " 'strategizes',\n",
       " 'stretch',\n",
       " 'student',\n",
       " 'submits',\n",
       " 'subscribe',\n",
       " 'subscribers',\n",
       " 'subscribing',\n",
       " 'subscription',\n",
       " 'substantially',\n",
       " 'successful',\n",
       " 'such',\n",
       " 'sucks',\n",
       " 'summer',\n",
       " 'supported',\n",
       " 'surveys',\n",
       " 'swagfriends',\n",
       " 'take',\n",
       " 'team',\n",
       " 'terrorism',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'then',\n",
       " 'these',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thousands',\n",
       " 'thumb',\n",
       " 'thumbs',\n",
       " 'thumsb',\n",
       " 'time',\n",
       " 'to',\n",
       " 'today',\n",
       " 'too',\n",
       " 'took',\n",
       " 'torunament',\n",
       " 'town',\n",
       " 'trade',\n",
       " 'transformed',\n",
       " 'transport',\n",
       " 'tried',\n",
       " 'trying',\n",
       " 'tvcmcadavid',\n",
       " 'twitter',\n",
       " 'two',\n",
       " 'type',\n",
       " 'up',\n",
       " 'upto',\n",
       " 'us',\n",
       " 'useful',\n",
       " 've',\n",
       " 'version',\n",
       " 'very',\n",
       " 'video',\n",
       " 'videos',\n",
       " 'views',\n",
       " 'vines',\n",
       " 'virgins',\n",
       " 'visit',\n",
       " 'voice',\n",
       " 'vouchers',\n",
       " 'waka',\n",
       " 'wallet',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'wasting',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'we',\n",
       " 'website',\n",
       " 'weebly',\n",
       " 'whats',\n",
       " 'when',\n",
       " 'whitney',\n",
       " 'who',\n",
       " 'why',\n",
       " 'wide',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'without',\n",
       " 'won',\n",
       " 'work',\n",
       " 'working',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worldcup',\n",
       " 'would',\n",
       " 'wow',\n",
       " 'write',\n",
       " 'xxx',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'youtube',\n",
       " 'youtubers',\n",
       " 'zonepa']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count1.get_feature_names()\n",
    "word_count2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_array1 = word_count1.transform(X_train)\n",
    "doc_array2 = word_count2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to array\n",
    "doc_array1 = word_count1.transform(X_train).toarray()\n",
    "doc_array2  = word_count2.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to dataframe\n",
    "feature_matrix1 = pd.DataFrame(doc_array1,columns = word_count1.get_feature_names())\n",
    "feature_matrix2 = pd.DataFrame(doc_array2,columns = word_count2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Naive Bayes Algorithm\n",
    "# import BernNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_BernNB = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BernNB.fit(feature_matrix1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model_BernNB.predict(feature_matrix2)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        39\n",
      "           1       0.97      0.80      0.88        35\n",
      "\n",
      "    accuracy                           0.89        74\n",
      "   macro avg       0.90      0.89      0.89        74\n",
      "weighted avg       0.90      0.89      0.89        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF and ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vectorizer\n",
    "## Importing TFIDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<296x1217 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4092 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying tfidf to data\n",
    "X_train_transformed = tfidf.fit_transform(X_train)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<74x1217 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1072 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed = tfidf.transform(X_test)\n",
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting transformed X_train_transformed on BernoulliNB\n",
    "model_BernNB.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_tfidf = model_BernNB.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.82        39\n",
      "           1       0.95      0.54      0.69        35\n",
      "\n",
      "    accuracy                           0.77        74\n",
      "   macro avg       0.83      0.76      0.75        74\n",
      "weighted avg       0.82      0.77      0.76        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_test_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
